{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "jupyter nbconvert ConvNCF.ipynb --to slides --reveal-prefix 'https://cdn.bootcss.com/reveal.js/3.5.0' --output ConvNCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Hello ConvNCF</h1>\n",
    "<p>Convolutional Neural Collaborative Filtering</p>\n",
    "\n",
    "___\n",
    "<p>speaker : Yi-Zhan Xu</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "大家好～我今天要報告的主題是利用ONCF做推薦系統，ONCF的全名是基於外積的神經協同過濾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Choice phobia</h1>\n",
    "<p>Hard to make decision</p>\n",
    "\n",
    "___\n",
    "<li>Why so many choices?</li>\n",
    "<li>Regret the decision</li>\n",
    "<li>Life is all about choices</li>\n",
    "<img src=\"https://i.imgur.com/Fb9HrGO.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "不知道大家有沒有選擇障礙的困擾，站在飲料店門口卻不知道該點什麼，像是每次出去吃飯，我都是最後一個決定好要吃什麼的人，然後別人都等得不耐煩哈哈。\n",
    "有選擇障礙的人總是有很多顧慮，並且希望可以下一個完美的決定，但往往事後又後悔當初怎麼沒選另外一個之類的...\n",
    "我是覺得說，其實生命就是由各種選擇所構成的，過去的選擇造就了今天的你。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>What should I do?</h1>\n",
    "\n",
    "___\n",
    "<li>Think what I got rather what I lost</li>\n",
    "<li>Choice the opinion of majority</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "回到選擇障礙的部分，那我們應該怎麼做才好呢？\n",
    "直覺什麼的在選擇障礙患者上是不管用的，應該要換一個角度思考。\n",
    "譬如說，從這次的選擇我會從中得到什麼，而不是因為害怕而逃避些什麼。\n",
    "如果真的沒辦法下決定，那不妨參考別人的建議吧，有時候多數人的決定也許是不錯的選擇。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Popular item</h1>\n",
    "<p>Rank the popularity</p>\n",
    "\n",
    "___\n",
    "<li>Low converge</li>\n",
    "<li>Not personalized</li>\n",
    "<li>Suitable for new user</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "最常見的推薦方法就是將商品的熱門程度排序，並從中挑選最熱門的的前幾個。\n",
    "譬如去餐廳吃飯時，可以選擇招牌菜或主廚推薦之類的。\n",
    "但這個方法無法推薦那些非熱門，但是也很好吃的商品，所以覆蓋率較低。\n",
    "而且這個方法缺少個人化的推薦，所以比較適合第一次光顧這家餐廳的客人，相對來說是無法滿足老饕們的需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Recommend system</h1>\n",
    "\n",
    "___\n",
    "<li>Association rule</li>\n",
    "<li>Content-based</li>\n",
    "<li>Collaborative Filtering</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "這邊我們介紹幾個比較常見的推薦系統，像是關聯規則、基於內容的推薦和協同過濾都是不錯的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Association rule</h1>\n",
    "<p>Shopping basket analysis</p>\n",
    "\n",
    "___\n",
    "<li>Frequent pattern</li>\n",
    "<li>Hard to focus on the product</li>\n",
    "<li>Violation of facts</li>\n",
    "<img src=\"https://edumine.files.wordpress.com/2013/09/market-basket-analysis.png\">\n",
    "<p>source : <a href=\"https://crmportals.com/blog/market-basket-analysis-a-recomender-system-with-many-business-possibilities/\">https://crmportals.com/blog/market-basket-analysis</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "首先是關連規則，透過過去顧客賣買的紀錄，我們希望可以找出一個顧客購買商品頻繁出現的pattern，像是買啤酒就一定會買尿布之類的。\n",
    "但是關聯規則在實務上卻不是這麼好用，因為這個方法是根據已知的pattern找出規則。\n",
    "譬如說最近爆發禽流感，想知道什麼樣的顧客會購買雞蛋，但在過去的紀錄中沒有出現和雞蛋有關的頻繁pattern，因此無法專注在某個我們想暸解的特定商品，所以不行透過預測實作我們的推薦系統。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Content-based</h1>\n",
    "\n",
    "___\n",
    "<li>Similarity of items</li>\n",
    "<li>Lack of discovery</li>\n",
    "<li>Cold start scenario</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "再來是基於內容的推薦系統，透過計算商品之間的相似度來找出最相似的進行推薦，譬如有人喜歡看名偵探柯南，那我們就可以推薦他其他和柯南相似的推理小說。\n",
    "但是這個方法只會基於原本的內容進行推薦，所以比較少有新的發現。而且當沒有已知的喜好內容時便無法進行推薦，造成所謂的冷啟動問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Collaborative Filtering</h1>\n",
    "<p>Personalized recommend system</p>\n",
    "\n",
    "___\n",
    "<li>Similarity of users</li>\n",
    "<li>Rating matrix</li>\n",
    "<li>Unexpected results</li>\n",
    "<img src=\"https://i.imgur.com/Aj7CXkA.png\">\n",
    "<p>source : <a href=\"https://medium.com/@cfpinela/recommender-systems-user-based-and-item-based-collaborative-filtering-5d5f375a127f\">https://medium.com/@cfpinela/recommender-systems</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "最後是我們的協同過濾，所謂協同是找出那些和使用者類似的人，而過濾則是預測個人的偏好，所以他是一種個人化的推薦系統。\n",
    "譬如圖中的問號，我們想預測使所者E對某部影片的喜好，首先要建立一個評分矩陣，因為BC和E一樣喜歡某本書，所以根據這個矩陣我們得知使用者E和B、C可能類似，又因為B、C對該影片的評分是不喜歡，所以推測使用者E的評分也會是不喜歡。因此這個方法也比起基於內容的方法有更多新的發現。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Feedback behavior</h1>\n",
    "\n",
    "___\n",
    "<li>Explicit (like or not)</li>\n",
    "<li>Implicit (browsing history)</li>\n",
    "<li>Positive sample</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "要實作協同過濾，首先我們要根據使用者對商品的反饋來建立評分矩陣，而反饋又可分為明確的反饋和含蓄的反饋。\n",
    "明確的反饋像是透過使用者的評分便可以明確的知道對商品的喜好，而含蓄的反饋則是透過購買或瀏覽紀錄。\n",
    "但單純透過瀏覽紀錄無法確切得知對商品的喜好，只能知道使用者對該商品有比較多的關注，所以這邊統一稱作positive的樣本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Matrix factorization</h1>\n",
    "<p>Split rating matirx into two matrix</p>\n",
    "\n",
    "___\n",
    "<li>Sparse data</li>\n",
    "<li>Latent factor (ID, gender, catrgory,...)</li>\n",
    "<li>Model-based</li>\n",
    "<img src=\"https://i.imgur.com/XAjshmN.png\">\n",
    "<p>source : <a href=\"https://jerrynest.io/recommender-system/\">https://jerrynest.io/recommender-system/</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "但是在實務中要取得使用者的評分是相當困難的，所以這邊我們只專注在implicit feedback的資料。\n",
    "只要使用者瀏覽過該商品的話，目標矩陣對應的的元素即為1，否則為0。\n",
    "因為使用者只會對特定的商品進行瀏覽，所以我們的評分矩陣是一個非常稀疏的矩陣。\n",
    "這邊我們透過透過矩陣分解的方法來解決資料稀疏的問題，根據潛在的特徵像是ID和性別等等，可以將評分矩陣分成P和Q兩個矩陣，逐步透過誤差反向傳遞，使PQ的乘積和目標矩陣相當靠近。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Embedding layer</h1>\n",
    "\n",
    "___\n",
    "<li>One-hot encoding</li>\n",
    "<li>Input two vectors $v_u\\in \\mathbb{R}^{M\\times1}$ and $v_i\\in \\mathbb{R}^{N\\times1}$</li>\n",
    "<li>Pre-train the P and Q using MF</li>\n",
    "<img src=\"https://i.imgur.com/AeQ8Vtx.png\">\n",
    "<img src=\"https://i.imgur.com/EIkJnGe.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "因為在協同過濾中只使用ID做為潛在的特徵，所以我們將使用者和商品的ID透過one hot encoding的方式進行編碼，分別得到$M\\times1$和$N\\times1$的兩個向量。\n",
    "再利用先前訓練好的兩個embedding matrix，轉置後和$v_u$及$v_i$相乘得到$p_u$和$q_i$兩個${k}\\times{1}$的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Interaction map</h1>\n",
    "\n",
    "___\n",
    "<li>Outer product</li>\n",
    "<li>Modeling the correlation</li>\n",
    "<li>Embedding size</li>\n",
    "<img src=\"https://i.imgur.com/gTg76RN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "相較於其他的協同過濾方法將$p_u$和$p_i$兩個向量concatenationc或做element wise product，我們這邊計算他們的外積，因為透過外積不但語意上來說更合理，還可以進一步計算相關性。\n",
    "另外embedding matrix中的K影響interaction map的大小，所以還需近一步考量參數K對模型的影響。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Convolutional neural network</h1>\n",
    "\n",
    "___\n",
    "<li>Feature detectors</li>\n",
    "<li>Local area</li>\n",
    "<li>High-order correlations</li>\n",
    "<li>Fewer parameters than MLP</li>\n",
    "<img src=\"https://i.imgur.com/dyca4MA.png\">\n",
    "<p>source : <a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf\">https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "有了interaction map我們就可以透過CNN來訓練模型。\n",
    "首先要介紹什麼是CNN，因為一張照片是由很多像素點所構成，所以如果我們要想讓電腦讀懂某張照片勢必只能一個一個元素分析。\n",
    "但有時候照片中的主角往往要從局部觀看才能暸解，譬如說近看是細胞，遠看是李政德。\n",
    "有鑒於CNN在影像辨識上有很好的效果，所以我們透過外積的方式將資料形同照片的格式來進行卷積。\n",
    "這邊我們使用32個2x2的filter在隱藏層中逐一掃過外積上每個點，因為下一層的元素是由上一層的filter所構成，所以每經過一層卷積相當於計算彼此間的correlation，最後再透過全連接層將向量轉換成最終預測的分數。\n",
    "總體來說使用CNN不但可以計算彼此間的correlation，而且和一般MLP多層感感知器的方法相比使用更少的參數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Target</h1>\n",
    "<p>Predict the matching score between user and item</p>\n",
    "\n",
    "___\n",
    "<li>ONCF framework</li>\n",
    "<li>Input : a user</li>\n",
    "<li>Output : recommend item list</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "所以我們的目標是希望在ONCF的框架下利用CNN，來近一步實作推薦系統。\n",
    "最終我們將輸入一位使用者，並決定推薦的個數，即可生成一個推薦商品的序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>ONCF framework</h1>\n",
    "\n",
    "___\n",
    "<li>Use MF to generate embedding layer</li>\n",
    "<li>Calculate interaction map by outer product</li>\n",
    "<li>Predict the score with CNN</li>\n",
    "<img src=\"https://i.imgur.com/9iSza4i.png\">\n",
    "<p>source : <a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf\">https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "就如同先前所說的，這就是我們最終ONCF的模型。\n",
    "我們首先利用MF的方法訓練得到兩個embedding matrx，在透過外積的方式得到形同照片的interaction map，最終利用CNN得到使用者對商品的預測分數，並從中選取k個進行推薦！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Bayesian Personalized Ranking</h1>\n",
    "<p>Accuracy depends on sorting</p>\n",
    "\n",
    "___\n",
    "<li>Relative order</li>\n",
    "<li>$(u, i, j)$</li>\n",
    "<li>Pairwise sample</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "為了要訓練ONCF的模型，我們得先介紹什麼是BPR。\n",
    "從多個樣本中選取特定少數個的商品進行推薦，本質上就是把商品排序後，並選取最前面的K個，所以再次凸顯了推薦結果中排序的重要性。\n",
    "在者因為在implicit feedback中我們無法得知使用者對商品的喜好，所以只能計算相對喜好的程度。\n",
    "譬如使用者瀏覽過$商品_i$但沒有瀏覽過$商品_j$，代表使用者比起$商品_j$更喜歡$商品_i$。\n",
    "所以我們便利用這BPR的方式得到多個pairwise的資料餵進模型中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Loss function</h1>\n",
    "\n",
    "___\n",
    "<li>Ranking-aware objective</li>\n",
    "<li>$\\hat y_{ui}$ = $w^Tg$</li>\n",
    "<li>Weight vector</li>\n",
    "<img src=\"https://i.imgur.com/V36Xi0H.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "有了BPR的資料後，我們便可以進一步計算使用者對$商品_i$和$商品_j$彼此間預測分數的誤差。\n",
    "因為只有相對喜歡的差異，所以$\\hat{y}_{ui}$和$\\hat{y}_{uj}$彼此間的差異愈大，代表愈能凸顯喜歡與否的程度。\n",
    "直得一提的是，全連接層中的w愈大將使得預測的分數愈大，所以我們須對w進行正規化。\n",
    "而這邊的lambda則是控制overfitting的參數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Regularization</h1>\n",
    "<p>Prevent from over-fitting</p>\n",
    "\n",
    "___\n",
    "<li>Embedding layer</li>\n",
    "<li>Convolution layer</li>\n",
    "<li>Prediction layer</li>\n",
    "<img src=\"https://i.imgur.com/vew5REy.png\">\n",
    "<p>source : <a href=\"http://mropengate.blogspot.com/2017/02/deep-learning-role-of-activation.html\">http://mropengate.blogspot.com/2017/02/deep-learning-role-of-activation.html</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "在深度學習中正規化扮演很重要的角色，譬如使用sigmoid當作激勵函數，當x為6大時y趨近1，而當x為無限大時y也趨近於1，事實上x=6和無限大有很大的差異，但activation function卻無法表現出這個事實。所以我們將x進行正規化，即可確保激勵函數對x的敏感度，以利於神經網路的學習。\n",
    "這邊我們分別對embedding, comvolution和prediction layer的參數進行正規化，確保最終有個較穩定的預測結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Hyper-parameters</h1>\n",
    "\n",
    "___\n",
    "<li>Feature map number</li>\n",
    "<li>Generalization ability</li>\n",
    "<img src=\"https://i.imgur.com/KBuF60b.png\">\n",
    "<p>source : <a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf\">https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "一個模型的好壞，參數的選取佔了很大一部分，這邊我們透過交叉驗證法探討feature map number對預測結果的影響。\n",
    "一般來說feature map的數量愈多代表考慮各種filter的可能，愈能反應卷積的效果，由圖中可發現不管我們C選取多少，都將使得結果收斂到一定的值，這也再次證明了在ONCF中使用CNN的可行性和穩定性，我們最終選取32當作feature map的數量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Datasets</h1>\n",
    "<p>Implicit feedback</p>\n",
    "\n",
    "___\n",
    "<li>Yelp</li>\n",
    "<li>Negative samples</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "如同先前所說的因為使用者鮮少對商品進行評分，所以我們專注在implicit feedback的探討。\n",
    "Yelp是一個有關於商業的資料集，共搜集了使用者和商品各約25000個，它本身是一個約有60e個元素的矩陣，而該資料集的rating卻只有約70w筆，再次凸顯評分矩陣的稀疏性。\n",
    "最後我們將training data中每位使用者的最後一筆記錄當作測試樣本(test ratings)，並且另外從列表中抽出999個先前未瀏覽過的商品(test negative)一并加入測試樣本。\n",
    "探討我們最終的推薦序列是否包含最後一筆的test ratings，計算預測的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Baselines</h1>\n",
    "\n",
    "___\n",
    "<li>ItemPop</li>\n",
    "<li>MF-BPR</li>\n",
    "<li>MLP</li>\n",
    "<li>JRL</li>\n",
    "<li>NeuMF</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "這邊我們和5個不同的分類方法進行比較，首先是ItemPop，顧名思義它是根據最熱們的商品進行推薦，因為缺乏個人化推薦的部分，所以只能作為推薦系統的標竿，來分析推薦的好壞與否。\n",
    "第二個是MF-BPR，利用BPR的pairwise來優化MF的模型，並計算user對item的預測分數。\n",
    "第三個是MLP，將embedding中的兩個向量利用concentation合併，餵進模型中來學習user和item間的interaction model。\n",
    "再來是JRL，他和MLP一樣是協同過濾的方法，差別在於它將embedding中的兩個向量進行element-wise product計算其correlation。\n",
    "最後是NeuMF，它結合了MLP和JRL的優點，是目前比較好的推薦方法。\n",
    "為了方便比較，這邊我們一率先用MF來pretrain embedding layer，並且embedding size皆為64。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Performance (i)</h1>\n",
    "<p>Top-K recommendation performance</p>\n",
    "\n",
    "___\n",
    "<li>HR</li>\n",
    "<li>NDCG</li>\n",
    "<li>Average improvement</li>\n",
    "<img src=\"https://i.imgur.com/64pEfRC.png\">\n",
    "<p>source : <a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf\">https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "這邊我們從1000個使用者先前未瀏覽過的商品中推薦K個，分別計算HR和NDCG來評估推薦的好壞。\n",
    "首先要介紹什麼是HR和NDCG，HR是衡量召回率用的，分母是所有的測試集合，分子是每位使用者在K個推薦序列中屬於測試的個數總和，所以當K=20時HR=0.8695相當於命中率約為8.6成。\n",
    "而NDCG全名是Normalized Discounted Cumulative Gain，因為排序的結果決定了推薦的好壞，並且針對排序錯誤項目的分數進行打折，又推薦個數可能不盡相同，所以在對其進行標準化，便得到了我們最終的NDCG分數，目標是使其分數愈大愈好。\n",
    "當K=20時，NDCG的值為0.6019。\n",
    "整體來說ConvNCF不管推薦個數如何都有很好的效果，比起多層感知器的方法平均改善了9%左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Performance (ii)</h1>\n",
    "<p>Different operations above embedding layer</p>\n",
    "\n",
    "___\n",
    "<li>Outer product</li>\n",
    "<li>Interaction function</li>\n",
    "<img src=\"https://i.imgur.com/EYdvTiH.png\">\n",
    "<p>source : <a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf\">https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "首先我們看到的是在embedding layer中使用不同方法的效果，我們想知道再embedding layer中使用不同的方法是否有差異。\n",
    "僅針對不同的embedding方法，像是concentation的MLP及elementWiseProduct的GMF和JRL。\n",
    "由圖中可發現ConvNCF的方法都有很好的結果，再次驗證使用outerproduct實作CNN的效果。\n",
    "而JRL的方法普遍比MLP的方法來的好，可能的原因是JRL計算embedding layer的correlation，而不像MLP只是純粹把兩個向量合併。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Performance (iii)</h1>\n",
    "<p>Different hidden layers for ONCF</p>\n",
    "\n",
    "___\n",
    "<li>CNN</li>\n",
    "<li>Semantics</li>\n",
    "<img src=\"https://i.imgur.com/8AbTyQJ.png\">\n",
    "<p>source : <a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf\">https://www.comp.nus.edu.sg/~xiangnan/papers/ijcai18-ConvNCF.pdf</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "接下來我們探討在隱藏層中使用不同方法的效果，想比較在outer product的框架上使用CNN和MLP的效果。\n",
    "為了公平比較我們將MLP的兩個向量坐外積，並命名為ONCF-mlp。\n",
    "由圖中可發現ConvNCF的效果是比較好的，這也再次證明了在outerproduct上使用CNN會使語意上來的更加合理。\n",
    "直得一提的是MLP的方法不但參數很多要訓練很久，而且效果還不及CNN的方法來的穩定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Data structure</h1>\n",
    "\n",
    "___\n",
    "<li>yelp.train.rating : [[user, item, rating, timestamp],...]</li>\n",
    "<li>yelp.test.rating : [[user, item, rating, timestamp],...]</li>\n",
    "<li>yelp.test.negative : [[(user, item), item1, item2, item3,...],...]</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "接著我們用作者提供的source code來實際操作一下，首先要先大概暸解一下資料型態。\n",
    "一共有三個檔案，分別是positive的rating，測試用的positive rating和negative list。\n",
    "這邊我們大概看一下每個檔案的第一行，第一個positive的rating是由使用者、商品和評分所構成，譬如$u_1$+$i_1$+3分，$u_1$+$i_2$+5分，其他以此類推，所以第一個檔案針對每個user都有很多的不同的item。\n",
    "第二個測試用的positive rating則是將每個使用者的對後一筆記錄當作測試用，藉由推薦k個從未瀏覽過的商品來觀察測試用的紀錄使否包含在推薦序列中。\n",
    "最後一個negative list則是從先前未瀏覽過的商品中均勻地抽出999個，並加入先前的測試用positive rating。\n",
    "根據每個使用者的1000個item，計算其user-item的分數，根據分數的高低排序，觀看測試用的positive rating是包含在前K個之中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Data preprocessing</h1>\n",
    "\n",
    "___\n",
    "<li>trainMatrix : [(user, item, 1),...]</li>\n",
    "<li>trianList : [[items],...]</li>\n",
    "<li>testRatings : [[user, item],...]</li>\n",
    "<li>testNegatives : [[items],...]</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "所以我們便開始讀取資料，經過一連串的資料預處理後得到四個重要的結果。\n",
    "首先trainMatrix是使用者對商品的評分，因為我們的目標是implicit data，所以只要有評分即標註為1，其本身是一個相當稀疏的矩陣，所以我們用(user,item,1)的方式儲存，來節省記憶體空間。\n",
    "第二個trainList是將每位使用者曾經評分過的每個項目放到list中，有了trainList便可以將user和item用encoding的方式呈現。\n",
    "第三個testRatings的目的和trainList相同，差別在於只保留最後一筆記錄。\n",
    "最後testNegativs則是將使用者未曾瀏覽過的item整理成多個list，方便我們模型的訓練。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Tensorboard</h1>\n",
    "<p>Visualization tool</p>\n",
    "\n",
    "___\n",
    "<li>Graph</li>\n",
    "<li>Embedding</li>\n",
    "<li>Loss</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "講了這麼多，還是看一下我們可視化的結果好了。\n",
    "首先是整個模型訓練的圖，這邊有兩個optimizer的原因是第一次訓練時參數是隨機初始化的，而之後的訓練則是根據正規化後的結果進行訓練。\n",
    "這邊演示了Embedding中的P和Q訓練的過程，預設P和Q的分配服從$N(0, 0.01)$，可以看到一開始的參數都在0附近，經過訓練後使得P和Q的參數介於-0.3~0.3之間，解決了資料稀疏的問題。\n",
    "最後是最重要的loss，由圖中可發現誤差逐漸變小會後趨近於，代表真實地反映出使用者喜歡i勝過j。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Demo</h1>\n",
    "\n",
    "___\n",
    "<li>HR</li>\n",
    "<li>NDCG</li>\n",
    "<li>AUC</li>\n",
    "<img src=\"https://i.imgur.com/trUMkWF.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "這是ConvNCF.py輸出的結果，因為我的電腦沒有GPU，所以那時候用google的雲端平台，但還是花了大概29小時。\n",
    "所以用這個方法實作推薦系統比較適合事先執行好，先根據已知的資料進行訓練，等到使用者有需要時便可以直推進行推薦。\n",
    "我們把焦點放在評估推薦系統常用的的指標HR、NDCG和AUC。\n",
    "而AUC則是透過ROC曲線下的面積計算TPR和FPR，可以反應正確判斷陽性的比例，最終AUC=0.9102代表推薦系統正確判斷喜歡的比例是不喜歡的0.92倍。\n",
    "所以整題來說，透過CNN實作ONCF的框架有著不錯的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Furthermore</h1>\n",
    "\n",
    "___\n",
    "<li>Sort the list</li>\n",
    "<li>Negative sampler</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "整體來說用CNN實作ONCF的框架是一個很棒的方法，但是HR和NDCG還有改善的空間。\n",
    "但目前的negative smaple是抽自均勻分配，可以在從這部分著手，或許會有更好的結果。\n",
    "再者可以使用看看目前推薦系統主流的L2 square loss來取代BPR loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Thanks</h1>\n",
    "\n",
    "___\n",
    "<img src=\"https://i.imgur.com/3sBnvkM.png\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
